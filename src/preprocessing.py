"""
ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” AI ì´ë¯¸ì§€ íŒë³„ ë°ì´í„°ì…‹ì„ Train/Validation/Testë¡œ ë¶„í• í•˜ê³ ,
ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì •ì˜í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    python src/preprocessing.py
"""

import os
import random
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# ëœë¤ ì‹œë“œ ê³ ì • (ì¬í˜„ì„±)
RANDOM_SEED = 42
random.seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)

# ì‹œê°í™” ì„¤ì •
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")


def setup_directories():
    """í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •"""
    project_root = Path(__file__).parent.parent
    data_dir = project_root / 'data' / 'raw'
    output_dir = project_root / 'data' / 'processed'
    results_dir = project_root / 'results' / 'figures'

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)
    results_dir.mkdir(parents=True, exist_ok=True)

    return {
        'project_root': project_root,
        'data_dir': data_dir,
        'output_dir': output_dir,
        'results_dir': results_dir,
        'fake_dir': data_dir / 'FAKE',
        'real_dir': data_dir / 'REAL'
    }


def collect_image_paths(dirs):
    """ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ìˆ˜ì§‘"""
    print("ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ìˆ˜ì§‘ ì¤‘...")

    fake_images = list(dirs['fake_dir'].glob('*.jpg')) + list(dirs['fake_dir'].glob('*.png'))
    real_images = list(dirs['real_dir'].glob('*.jpg')) + list(dirs['real_dir'].glob('*.png'))

    print(f"\nFAKE ì´ë¯¸ì§€: {len(fake_images):,}ê°œ")
    print(f"REAL ì´ë¯¸ì§€: {len(real_images):,}ê°œ")
    print(f"ì „ì²´ ì´ë¯¸ì§€: {len(fake_images) + len(real_images):,}ê°œ")

    # ê²½ë¡œì™€ ë ˆì´ë¸” ìƒì„±
    image_paths = fake_images + real_images
    labels = [0] * len(fake_images) + [1] * len(real_images)  # 0: FAKE, 1: REAL

    return image_paths, labels


def split_dataset(image_paths, labels):
    """ë°ì´í„°ì…‹ì„ Train/Validation/Testë¡œ ë¶„í• """
    print("\n" + "="*60)
    print("ë°ì´í„° ë¶„í•  ì¤‘...")
    print("="*60)

    # Train / (Val + Test) ë¶„í•  (70% / 30%)
    train_paths, temp_paths, train_labels, temp_labels = train_test_split(
        image_paths,
        labels,
        test_size=0.3,
        stratify=labels,
        random_state=RANDOM_SEED
    )

    print(f"\n1ë‹¨ê³„: Train / Temp ë¶„í• ")
    print(f"  Train: {len(train_paths):,}ê°œ ({len(train_paths)/len(image_paths)*100:.1f}%)")
    print(f"  Temp:  {len(temp_paths):,}ê°œ ({len(temp_paths)/len(image_paths)*100:.1f}%)")

    # Val / Test ë¶„í•  (ê°ê° 15%)
    val_paths, test_paths, val_labels, test_labels = train_test_split(
        temp_paths,
        temp_labels,
        test_size=0.5,  # 30%ì˜ ì ˆë°˜ = 15%
        stratify=temp_labels,
        random_state=RANDOM_SEED
    )

    print(f"\n2ë‹¨ê³„: Val / Test ë¶„í• ")
    print(f"  Val:   {len(val_paths):,}ê°œ ({len(val_paths)/len(image_paths)*100:.1f}%)")
    print(f"  Test:  {len(test_paths):,}ê°œ ({len(test_paths)/len(image_paths)*100:.1f}%)")

    return {
        'train': (train_paths, train_labels),
        'val': (val_paths, val_labels),
        'test': (test_paths, test_labels)
    }


def print_split_statistics(splits):
    """ë¶„í•  ê²°ê³¼ í†µê³„ ì¶œë ¥"""
    print("\n" + "="*60)
    print("ë°ì´í„° ë¶„í•  ê²°ê³¼ (í´ë˜ìŠ¤ë³„)")
    print("="*60)

    for split_name, (paths, labels) in splits.items():
        fake_count = labels.count(0)
        real_count = labels.count(1)
        total = len(paths)

        print(f"\n{split_name.upper()} Set: {total:,}ê°œ")
        print(f"  FAKE: {fake_count:,}ê°œ ({fake_count/total*100:.1f}%)")
        print(f"  REAL: {real_count:,}ê°œ ({real_count/total*100:.1f}%)")

    print("\n" + "="*60)
    print("âœ… í´ë˜ìŠ¤ ê· í˜•ì´ ëª¨ë“  ì„¸íŠ¸ì—ì„œ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤!")
    print("="*60)


def save_to_csv(splits, output_dir):
    """ë¶„í• ëœ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥"""
    print("\n" + "="*60)
    print("CSV íŒŒì¼ ì €ì¥ ì¤‘...")
    print("="*60)

    for split_name, (paths, labels) in splits.items():
        df = pd.DataFrame({
            'image_path': [str(p) for p in paths],
            'label': labels
        })

        csv_path = output_dir / f'{split_name}.csv'
        df.to_csv(csv_path, index=False)
        print(f"  âœ“ {split_name}.csv ({len(df):,}ê°œ) ì €ì¥ ì™„ë£Œ")

    print(f"\nì €ì¥ ìœ„ì¹˜: {output_dir}")
    print("="*60)


def visualize_split_distribution(splits, results_dir):
    """ë¶„í•  ê²°ê³¼ ì‹œê°í™”"""
    print("\nì‹œê°í™” ìƒì„± ì¤‘...")

    # ë°ì´í„° ì¤€ë¹„
    datasets = []
    fake_counts = []
    real_counts = []

    for split_name, (paths, labels) in splits.items():
        datasets.append(split_name.capitalize())
        fake_counts.append(labels.count(0))
        real_counts.append(labels.count(1))

    # ë§‰ëŒ€ ê·¸ë˜í”„
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    colors = ['#FF6B6B', '#4ECDC4']

    for ax, dataset, fake, real in zip(axes, datasets, fake_counts, real_counts):
        bars = ax.bar(['FAKE', 'REAL'], [fake, real], color=colors,
                     alpha=0.7, edgecolor='black', linewidth=2)
        ax.set_title(f'{dataset} Set', fontsize=14, fontweight='bold')
        ax.set_ylabel('ì´ë¯¸ì§€ ê°œìˆ˜', fontsize=12)
        ax.grid(axis='y', alpha=0.3)

        # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{int(height):,}',
                   ha='center', va='bottom', fontsize=11, fontweight='bold')

    plt.suptitle('Train/Validation/Test ë¶„í•  ê²°ê³¼', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()

    save_path = results_dir / 'data_split_distribution.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ë¶„í•  ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥: {save_path.name}")

    # íŒŒì´ ì°¨íŠ¸
    fig, ax = plt.subplots(figsize=(8, 8))

    sizes = [len(paths) for paths, _ in splits.values()]
    labels_pie = ['Train\n(70%)', 'Validation\n(15%)', 'Test\n(15%)']
    colors_pie = ['#FF9999', '#66B2FF', '#99FF99']
    explode = (0.05, 0, 0)

    wedges, texts, autotexts = ax.pie(
        sizes,
        labels=labels_pie,
        colors=colors_pie,
        autopct='%1.1f%%',
        startangle=90,
        explode=explode,
        shadow=True,
        textprops={'fontsize': 12, 'fontweight': 'bold'}
    )

    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontsize(14)

    ax.set_title('ë°ì´í„°ì…‹ ë¶„í•  ë¹„ìœ¨', fontsize=16, fontweight='bold', pad=20)

    save_path = results_dir / 'data_split_ratio.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ë¶„í•  ë¹„ìœ¨ íŒŒì´ ì°¨íŠ¸ ì €ì¥: {save_path.name}")


def print_summary(output_dir, results_dir):
    """ì‘ì—… ìš”ì•½ ì¶œë ¥"""
    print("\n" + "="*60)
    print("ì‘ì—… ì™„ë£Œ!")
    print("="*60)
    print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"\nCSV íŒŒì¼ ({output_dir}):")
    print("  - train.csv")
    print("  - val.csv")
    print("  - test.csv")
    print(f"\nì‹œê°í™” íŒŒì¼ ({results_dir}):")
    print("  - data_split_distribution.png")
    print("  - data_split_ratio.png")
    print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("  Phase 4: PyTorch Dataset & DataLoader êµ¬í˜„")
    print("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*60)
    print("AI ì´ë¯¸ì§€ íŒë³„ - ë°ì´í„° ì „ì²˜ë¦¬")
    print("="*60)
    print(f"Random Seed: {RANDOM_SEED}\n")

    # 1. ë””ë ‰í† ë¦¬ ì„¤ì •
    dirs = setup_directories()

    # 2. ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
    image_paths, labels = collect_image_paths(dirs)

    # 3. ë°ì´í„° ë¶„í• 
    splits = split_dataset(image_paths, labels)

    # 4. í†µê³„ ì¶œë ¥
    print_split_statistics(splits)

    # 5. CSV ì €ì¥
    save_to_csv(splits, dirs['output_dir'])

    # 6. ì‹œê°í™”
    visualize_split_distribution(splits, dirs['results_dir'])

    # 7. ìš”ì•½
    print_summary(dirs['output_dir'], dirs['results_dir'])


if __name__ == "__main__":
    main()
