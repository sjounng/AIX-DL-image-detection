# AI ì´ë¯¸ì§€ íŒë³„ í”„ë¡œì íŠ¸ - ê°œë°œ ê°€ì´ë“œ

## ê°œë°œ ë‹¨ê³„ (Development Steps)

ì´ ë¬¸ì„œëŠ” AI ìƒì„± ì´ë¯¸ì§€ íŒë³„ í”„ë¡œì íŠ¸ì˜ ì „ì²´ ê°œë°œ ë‹¨ê³„ë¥¼ ì •ë¦¬í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## Phase 1: í™˜ê²½ ì„¤ì • (Environment Setup)

### 1.1 requirements.txt ì‘ì„± 
**ëª©í‘œ**: í”„ë¡œì íŠ¸ì— í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ì˜

**í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬**:
- PyTorch + torchvision (ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬)
- numpy, pandas (ë°ì´í„° ì²˜ë¦¬)
- matplotlib, seaborn, plotly (ì‹œê°í™”)
- Pillow, opencv-python (ì´ë¯¸ì§€ ì²˜ë¦¬)
- scikit-learn (í‰ê°€ ì§€í‘œ)
- albumentations (ë°ì´í„° ì¦ê°•)
- tensorboard (í•™ìŠµ ëª¨ë‹ˆí„°ë§)
- jupyter, ipykernel (ë…¸íŠ¸ë¶)

**ê²°ê³¼ë¬¼**: `requirements.txt`

### 1.2 ê°€ìƒí™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜ 
**ëª©í‘œ**: ê°œë°œ í™˜ê²½ êµ¬ì¶•

**ëª…ë ¹ì–´**:
```bash
# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# ì„¤ì¹˜ í™•ì¸
python -c "import torch; print(torch.__version__)"
```

**ê²°ê³¼ë¬¼**: ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ

---

## Phase 2: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ (EDA) 

### 2.1 ë°ì´í„° ê¸°ë³¸ ì •ë³´ í™•ì¸
**ëª©í‘œ**: ë°ì´í„°ì…‹ì˜ êµ¬ì¡°ì™€ í¬ê¸° íŒŒì•…

**ì‘ì—… ë‚´ìš©**:
- ì´ ì´ë¯¸ì§€ ìˆ˜ í™•ì¸
- í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸ (FAKE vs REAL)
- ë°ì´í„° ê· í˜• ê²€ì¦

### 2.2 ì´ë¯¸ì§€ íŠ¹ì„± ë¶„ì„
**ëª©í‘œ**: ì´ë¯¸ì§€ì˜ ë¬¼ë¦¬ì  íŠ¹ì„± íŒŒì•…

**ì‘ì—… ë‚´ìš©**:
- ì´ë¯¸ì§€ í¬ê¸° ë¶„í¬ (ë„ˆë¹„, ë†’ì´)
- ì´ë¯¸ì§€ í•´ìƒë„ ë²”ìœ„
- íŒŒì¼ í¬ê¸° ë¶„í¬
- ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™” (ê° í´ë˜ìŠ¤ë³„ 10ê°œì”©)

### 2.3 ìƒ‰ìƒ ë° í†µê³„ ë¶„ì„
**ëª©í‘œ**: ì´ë¯¸ì§€ì˜ ìƒ‰ìƒ íŒ¨í„´ ë¶„ì„

**ì‘ì—… ë‚´ìš©**:
- RGB ì±„ë„ë³„ ë¶„í¬
- FAKE vs REAL ìƒ‰ìƒ ì°¨ì´
- í†µê³„ ìš”ì•½ í…Œì´ë¸”

**ê²°ê³¼ë¬¼**: `notebooks/01_EDA.ipynb`

**ì£¼ìš” ë°œê²¬**:
- í´ë˜ìŠ¤ ê· í˜•: FAKEì™€ REAL ê°ê° ì•½ 20,000ê°œ
- ì´ë¯¸ì§€ í¬ê¸° ë‹¤ì–‘ â†’ ë¦¬ì‚¬ì´ì§• í•„ìš” (224x224 ì¶”ì²œ)
- ìƒ‰ìƒ ë¶„í¬ ì°¨ì´ ì¡´ì¬ â†’ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥ íŠ¹ì§•

---

## Phase 3: ë°ì´í„° ì „ì²˜ë¦¬ (Data Preprocessing)

### 3.1 ë°ì´í„° ë¶„í• 
**ëª©í‘œ**: Train/Validation/Test ì„¸íŠ¸ ë¶„í• 

**ë¶„í•  ë¹„ìœ¨**:
- Training: 70% (~28,000ì¥: 14,000 FAKE + 14,000 REAL)
- Validation: 15% (~6,000ì¥: 3,000 FAKE + 3,000 REAL)
- Test: 15% (~6,000ì¥: 3,000 FAKE + 3,000 REAL)

**ì‘ì—… ë‚´ìš©**:
```python
from sklearn.model_selection import train_test_split

# ë°ì´í„° ë¶„í•  ë¡œì§
# - Stratified split (í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)
# - Random seed ê³ ì • (ì¬í˜„ì„±)
```

### 3.2 ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
**ëª©í‘œ**: í•™ìŠµì„ ìœ„í•œ ì´ë¯¸ì§€ í‘œì¤€í™”

**ì „ì²˜ë¦¬ ë‹¨ê³„**:
1. **ë¦¬ì‚¬ì´ì§•**: 224x224 ë˜ëŠ” 256x256
2. **ì •ê·œí™”**:
   - ImageNet í‰ê· /í‘œì¤€í¸ì°¨ ì‚¬ìš©
   - mean=[0.485, 0.456, 0.406]
   - std=[0.229, 0.224, 0.225]
3. **ë°ì´í„° ì¦ê°• (Training only)**:
   - Random Horizontal Flip (p=0.5)
   - Random Rotation (Â±15ë„)
   - Random Brightness/Contrast ì¡°ì •
   - Color Jitter

**ì‘ì—… ë‚´ìš©**:
```python
from torchvision import transforms
from albumentations import (
    Compose, HorizontalFlip, Rotate,
    ColorJitter, Normalize, Resize
)

# Transform ì •ì˜
train_transform = Compose([...])
val_test_transform = Compose([...])
```

**ê²°ê³¼ë¬¼**:
- `notebooks/02_preprocessing.ipynb`
- `data/processed/train/`, `data/processed/val/`, `data/processed/test/`

---

## Phase 4: ë°ì´í„° ë¡œë” êµ¬í˜„

### 4.1 PyTorch Dataset í´ë˜ìŠ¤
**ëª©í‘œ**: ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ êµ¬í˜„

**ì‘ì—… ë‚´ìš©**:
```python
from torch.utils.data import Dataset

class AIImageDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ë³€í™˜
        pass
```

### 4.2 DataLoader ì„¤ì •
**ëª©í‘œ**: ë°°ì¹˜ ì²˜ë¦¬ ë° íš¨ìœ¨ì ì¸ ë°ì´í„° ë¡œë”©

**í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
- Batch size: 32 (ë˜ëŠ” 64)
- Shuffle: True (training), False (val/test)
- Num workers: 4 (CPU ì½”ì–´ ìˆ˜ì— ë”°ë¼ ì¡°ì •)
- Pin memory: True (GPU ì‚¬ìš© ì‹œ)

**ì‘ì—… ë‚´ìš©**:
```python
from torch.utils.data import DataLoader

train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,
    pin_memory=True
)
```

**ê²°ê³¼ë¬¼**: `src/data_loader.py`

---

## Phase 5: ëª¨ë¸ êµ¬í˜„

### 5.1 ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ (ê°„ë‹¨í•œ CNN)
**ëª©í‘œ**: ì„±ëŠ¥ ê¸°ì¤€ì  ì„¤ì •

**ëª¨ë¸ êµ¬ì¡°**:
```
Input (3, 224, 224)
    â†“
Conv2D (64) â†’ ReLU â†’ MaxPool
    â†“
Conv2D (128) â†’ ReLU â†’ MaxPool
    â†“
Conv2D (256) â†’ ReLU â†’ MaxPool
    â†“
Flatten â†’ Dense (512) â†’ ReLU â†’ Dropout(0.5)
    â†“
Dense (2) â†’ Softmax
```

**ì‘ì—… ë‚´ìš©**:
```python
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self, num_classes=2):
        super(SimpleCNN, self).__init__()
        # ë ˆì´ì–´ ì •ì˜
        pass

    def forward(self, x):
        # Forward pass
        pass
```

### 5.2 ì „ì´í•™ìŠµ ëª¨ë¸ë“¤
**ëª©í‘œ**: ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ë¡œ ì„±ëŠ¥ í–¥ìƒ

**ëª¨ë¸ í›„ë³´**:

#### A. ResNet50
- **íŠ¹ì§•**: Residual Connectionìœ¼ë¡œ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµ
- **íŒŒë¼ë¯¸í„°**: ~25M
- **ì¥ì **: ì•ˆì •ì ì¸ í•™ìŠµ, ë†’ì€ ì„±ëŠ¥

```python
import torchvision.models as models

resnet50 = models.resnet50(pretrained=True)
resnet50.fc = nn.Linear(2048, 2)  # ë§ˆì§€ë§‰ ë ˆì´ì–´ êµì²´
```

#### B. EfficientNetB0
- **íŠ¹ì§•**: íš¨ìœ¨ì ì¸ ëª¨ë¸ ìŠ¤ì¼€ì¼ë§
- **íŒŒë¼ë¯¸í„°**: ~5M
- **ì¥ì **: ì ì€ íŒŒë¼ë¯¸í„°, ë¹ ë¥¸ í•™ìŠµ

```python
from torchvision.models import efficientnet_b0

efficientnet = efficientnet_b0(pretrained=True)
efficientnet.classifier[1] = nn.Linear(1280, 2)
```

#### C. VGG16
- **íŠ¹ì§•**: ë‹¨ìˆœí•˜ì§€ë§Œ ê°•ë ¥í•œ êµ¬ì¡°
- **íŒŒë¼ë¯¸í„°**: ~138M
- **ì¥ì **: ì „ì´í•™ìŠµ ë²¤ì¹˜ë§ˆí¬

```python
vgg16 = models.vgg16(pretrained=True)
vgg16.classifier[6] = nn.Linear(4096, 2)
```

### 5.3 ëª¨ë¸ í•™ìŠµ ì „ëµ
**Fine-tuning ì „ëµ**:
1. **Feature Extraction**:
   - ì‚¬ì „í•™ìŠµëœ ë ˆì´ì–´ ë™ê²°
   - ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ í•™ìŠµ
2. **Fine-tuning**:
   - ì „ì²´ ë ˆì´ì–´ í•™ìŠµ
   - ë‚®ì€ learning rate ì‚¬ìš©

**ê²°ê³¼ë¬¼**:
- `src/models.py`
- `notebooks/03_baseline_model.ipynb`

---

## Phase 6: í•™ìŠµ íŒŒì´í”„ë¼ì¸

### 6.1 í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
**ëª©í‘œ**: ëª¨ë¸ í•™ìŠµ ìë™í™”

**í•˜ì´í¼íŒŒë¼ë¯¸í„°**:
```python
HYPERPARAMETERS = {
    'learning_rate': 0.001,
    'batch_size': 32,
    'epochs': 50,
    'optimizer': 'Adam',
    'loss_function': 'CrossEntropyLoss',
    'weight_decay': 1e-4,
    'dropout': 0.5
}
```

**í•™ìŠµ ë¡œì§**:
```python
def train_one_epoch(model, loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0

    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    return running_loss / len(loader)
```

### 6.2 ê²€ì¦ ë° í‰ê°€
**ëª©í‘œ**: ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

**í‰ê°€ ì§€í‘œ**:
- **Accuracy**: ì „ì²´ ì •í™•ë„
- **Precision**: AI ìƒì„±ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œ ë¹„ìœ¨
- **Recall**: ì‹¤ì œ AI ìƒì„±ì„ ì˜¬ë°”ë¥´ê²Œ íƒì§€í•œ ë¹„ìœ¨
- **F1-Score**: Precisionê³¼ Recallì˜ ì¡°í™”í‰ê· 
- **ROC-AUC**: ëª¨ë¸ì˜ ì „ë°˜ì  ì„±ëŠ¥

**ê²€ì¦ ë¡œì§**:
```python
def validate(model, loader, criterion, device):
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = correct / total
    return val_loss / len(loader), accuracy
```

### 6.3 ëª¨ë¸ ì €ì¥ ë° ì¡°ê¸° ì¢…ë£Œ
**ëª©í‘œ**: ìµœì  ëª¨ë¸ ì €ì¥ ë° ê³¼ì í•© ë°©ì§€

**Early Stopping**:
```python
early_stopping_patience = 5
best_val_loss = float('inf')
patience_counter = 0

if val_loss < best_val_loss:
    best_val_loss = val_loss
    torch.save(model.state_dict(), 'models/best_model.pth')
    patience_counter = 0
else:
    patience_counter += 1
    if patience_counter >= early_stopping_patience:
        print("Early stopping triggered")
        break
```

**Learning Rate Scheduler**:
```python
from torch.optim.lr_scheduler import ReduceLROnPlateau

scheduler = ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.1,
    patience=3
)
```

**ê²°ê³¼ë¬¼**:
- `src/train.py`
- `notebooks/04_final_model.ipynb`
- `models/best_model.pth`

---

## Phase 7: í‰ê°€ ë° ë¶„ì„

### 7.1 ì„±ëŠ¥ í‰ê°€
**ëª©í‘œ**: Test setì—ì„œ ìµœì¢… ì„±ëŠ¥ ì¸¡ì •

**í‰ê°€ í•­ëª©**:
1. **Confusion Matrix**:
```python
from sklearn.metrics import confusion_matrix, classification_report

y_true = []
y_pred = []

# ì˜ˆì¸¡ ìˆ˜ì§‘
with torch.no_grad():
    for images, labels in test_loader:
        outputs = model(images.to(device))
        _, predicted = torch.max(outputs, 1)
        y_true.extend(labels.numpy())
        y_pred.extend(predicted.cpu().numpy())

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
print(classification_report(y_true, y_pred))
```

2. **ROC Curve & AUC**:
```python
from sklearn.metrics import roc_curve, auc

fpr, tpr, _ = roc_curve(y_true, y_scores)
roc_auc = auc(fpr, tpr)

plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
```

### 7.2 ì‹œê°í™”
**ëª©í‘œ**: í•™ìŠµ ê³¼ì • ë° ê²°ê³¼ ì‹œê°í™”

**ì‹œê°í™” í•­ëª©**:
1. **í•™ìŠµ ê³¡ì„ **:
   - Training Loss vs Validation Loss
   - Training Accuracy vs Validation Accuracy

2. **Grad-CAM**:
   - ëª¨ë¸ì´ ì£¼ëª©í•˜ëŠ” ì˜ì—­ ì‹œê°í™”
   - FAKE/REAL ê°ê°ì˜ ì¤‘ìš” íŠ¹ì§• í™•ì¸

```python
from pytorch_grad_cam import GradCAM

cam = GradCAM(model=model, target_layers=[model.layer4[-1]])
grayscale_cam = cam(input_tensor=input_image)
```

3. **ì˜¤ë¶„ë¥˜ ì‚¬ë¡€ ë¶„ì„**:
   - False Positive: ì‹¤ì œë¥¼ AIë¡œ ì˜ëª» ë¶„ë¥˜
   - False Negative: AIë¥¼ ì‹¤ì œë¡œ ì˜ëª» ë¶„ë¥˜
   - ê° ì‚¬ë¡€ì˜ íŠ¹ì§• ë¶„ì„

### 7.3 ëª¨ë¸ ë¹„êµ
**ëª©í‘œ**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµ

**ë¹„êµ í…Œì´ë¸”**:
| ëª¨ë¸ | Accuracy | Precision | Recall | F1-Score | Training Time | Params |
|------|----------|-----------|--------|----------|---------------|---------|
| SimpleCNN | TBD | TBD | TBD | TBD | TBD | ~5M |
| ResNet50 | TBD | TBD | TBD | TBD | TBD | ~25M |
| EfficientNetB0 | TBD | TBD | TBD | TBD | TBD | ~5M |
| VGG16 | TBD | TBD | TBD | TBD | TBD | ~138M |

**ê²°ê³¼ë¬¼**:
- `src/evaluate.py`
- `results/figures/` (ëª¨ë“  ê·¸ë˜í”„)
- `results/metrics/` (í‰ê°€ ì§€í‘œ CSV)
- `results/reports/` (ë¶„ì„ ë³´ê³ ì„œ)

---

## Phase 8: ë¬¸ì„œí™” ë° ë§ˆë¬´ë¦¬

### 8.1 README.md ì—…ë°ì´íŠ¸
**ëª©í‘œ**: ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¬¸ì„œì— ë°˜ì˜

**ì—…ë°ì´íŠ¸ í•­ëª©**:
- Section IV: Evaluation & Analysis
  - ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ì‘ì„±
  - í•™ìŠµ ê³¡ì„  ì´ë¯¸ì§€ ì¶”ê°€
  - Confusion Matrix ì¶”ê°€
  - ì£¼ìš” ë°œê²¬ ì‚¬í•­ ì‘ì„±

- Section VI: Conclusion
  - ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë° ì •í™•ë„
  - ì£¼ìš” ë°œê²¬ ì‚¬í•­
  - í•œê³„ì  ë° ê°œì„  ë°©í–¥
  - ë°°ìš´ ì 

### 8.2 ë°œí‘œ ìë£Œ/ì˜ìƒ ì¤€ë¹„
**ëª©í‘œ**: í”„ë¡œì íŠ¸ ê²°ê³¼ ë°œí‘œ

**ë°œí‘œ êµ¬ì„±** (5-10ë¶„):
1. í”„ë¡œì íŠ¸ ì†Œê°œ ë° ë™ê¸° (1ë¶„)
2. ë°ì´í„°ì…‹ ì„¤ëª… (1ë¶„)
3. ëª¨ë¸ êµ¬ì¡° ë° í•™ìŠµ ê³¼ì • (2-3ë¶„)
4. ê²°ê³¼ ë¶„ì„ ë° ì‹œì—° (2-3ë¶„)
5. ê²°ë¡  ë° ë°°ìš´ ì  (1ë¶„)

**ë°œí‘œ ìë£Œ**:
- `docs/presentation.pdf` ë˜ëŠ” PPT
- ë°ëª¨ ì˜ìƒ ë˜ëŠ” ë¼ì´ë¸Œ ì‹œì—°

### 8.3 ì½”ë“œ ì •ë¦¬ ë° ë¦¬íŒ©í† ë§
**ëª©í‘œ**: ì½”ë“œ í’ˆì§ˆ í–¥ìƒ

**ì •ë¦¬ í•­ëª©**:
- [ ] ì£¼ì„ ì¶”ê°€
- [ ] Docstring ì‘ì„±
- [ ] ë¶ˆí•„ìš”í•œ ì½”ë“œ ì œê±°
- [ ] ì½”ë“œ ìŠ¤íƒ€ì¼ í†µì¼ (PEP8)
- [ ] í•¨ìˆ˜/í´ë˜ìŠ¤ ì¬ì‚¬ìš©ì„± ê°œì„ 

**ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸**:
- [ ] ëª¨ë“  ë…¸íŠ¸ë¶ì´ ì—ëŸ¬ ì—†ì´ ì‹¤í–‰ë˜ëŠ”ê°€?
- [ ] README.mdê°€ ìµœì‹  ìƒíƒœì¸ê°€?
- [ ] ê²°ê³¼ íŒŒì¼ë“¤ì´ ì ì ˆíˆ ì €ì¥ë˜ì—ˆëŠ”ê°€?
- [ ] .gitignoreê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ê°€?
- [ ] ë°œí‘œ ìë£Œê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ê°€?

---

## ğŸ“Š ê¶Œì¥ ì‘ì—… ì¼ì •

### Week 1: í™˜ê²½ ì„¤ì • ë° ë°ì´í„° íƒìƒ‰
- âœ… Phase 1: í™˜ê²½ ì„¤ì • (ì™„ë£Œ)
- âœ… Phase 2: EDA (ì™„ë£Œ)

### Week 2: ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¡œë”
- Phase 3: ë°ì´í„° ì „ì²˜ë¦¬
- Phase 4: ë°ì´í„° ë¡œë” êµ¬í˜„

### Week 3: ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸
- Phase 5.1: SimpleCNN êµ¬í˜„
- Phase 6: í•™ìŠµ íŒŒì´í”„ë¼ì¸ (ë² ì´ìŠ¤ë¼ì¸)

### Week 4: ì „ì´í•™ìŠµ ëª¨ë¸
- Phase 5.2: ResNet50, EfficientNet, VGG16
- Phase 6: ê° ëª¨ë¸ í•™ìŠµ ë° ë¹„êµ

### Week 5: í‰ê°€ ë° ë¬¸ì„œí™”
- Phase 7: í‰ê°€ ë° ì‹œê°í™”
- Phase 8: ë¬¸ì„œí™” ë° ë°œí‘œ ì¤€ë¹„

---

## ğŸ¯ í˜„ì¬ ì§„í–‰ ìƒí™©

- [x] Phase 1.1: requirements.txt ì‘ì„±
- [x] Phase 1.2: íŒ¨í‚¤ì§€ ì„¤ì¹˜
- [x] Phase 2: EDA ë…¸íŠ¸ë¶ ì‘ì„±
- [ ] Phase 3: ë°ì´í„° ì „ì²˜ë¦¬
- [ ] Phase 4: ë°ì´í„° ë¡œë”
- [ ] Phase 5: ëª¨ë¸ êµ¬í˜„
- [ ] Phase 6: í•™ìŠµ íŒŒì´í”„ë¼ì¸
- [ ] Phase 7: í‰ê°€ ë° ë¶„ì„
- [ ] Phase 8: ë¬¸ì„œí™”

---

## ğŸ’¡ ì¶”ê°€ ì°¸ê³  ì‚¬í•­

### ìœ ìš©í•œ ë¦¬ì†ŒìŠ¤
- [PyTorch ê³µì‹ íŠœí† ë¦¬ì–¼](https://pytorch.org/tutorials/)
- [Transfer Learning Guide](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- [Grad-CAM ë…¼ë¬¸](https://arxiv.org/abs/1610.02391)

### íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡± â†’ Batch size ì¤„ì´ê¸°
- ê³¼ì í•© â†’ Dropout, Data Augmentation ê°•í™”
- í•™ìŠµ ì†ë„ ëŠë¦¼ â†’ num_workers ì¡°ì •, Mixed Precision Training

### ì‹¤í—˜ ê´€ë¦¬
- TensorBoardë¡œ í•™ìŠµ ê³¼ì • ê¸°ë¡
- ê° ì‹¤í—˜ë§ˆë‹¤ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë¡
- ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³„ë„ ì €ì¥

---

**Last Updated**: 2024-11-24
